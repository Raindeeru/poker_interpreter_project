{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15249185-5670-4802-982c-74e822f9311d",
   "metadata": {},
   "source": [
    "# Section 1. Introduction to the Problem/Task and Interpreter System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdff9c-9aeb-4c99-adab-8f337b0ae555",
   "metadata": {},
   "source": [
    "An Interpreter System is a type of program that executes instructions written in a specific language without needing to be compiled into a machine code. It process commanda line by line or statement by statement providing real-time feedback and execution, dynamic interaction, flexibility, debugging and testing efficiency, making them valuable tools for both development and interactive applications.\n",
    "\n",
    "For this project, our group chose a Command Interpreter System that serves as a core mechanic of a text-based RPG Poker Game, using commands such as (start, bet, fold, call, all, raise, buy, inspect, play, quit, use, etc.), to manipulate the events within the game. With each command triggering corresponding game functions such as (Starting the game, Betting a certain amount of chips, Forfeiting Hand, etc.). These commands and functions becomes the bridge between user input and in-game outcomes.\n",
    "\n",
    "The chosen interpreter system was selected due to its capability to facilitate and support interactive gameplay and real-time decision-making, making players engage directly through the system, emphasizing logic and strategy whilst implementing practical applications of interpreter systems in game development, parsing, validating, and executing structured inputs.\n",
    "\n",
    "The target task of this interpreter is to execute and manage gameplay commands by interpreting textual inputs by the user which is then validated through parameters with command evaluations to detect error inputs by users, and translates them into corresponding events or actions within the game. Through this, the interpreter ensures a smooth command-driven experience, enabling players to progress through increasingly challenging poker battles while managing resources and strategies via intuitive text-based interactions.\n",
    "\n",
    "In conclusion, our command interpreter system transforms a sequence of user inputs into a proper foundation for an interactive game environment that highlights technical functionality, creative application, and feedback efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103d247-11fe-47fa-b2fe-d226024c99ad",
   "metadata": {},
   "source": [
    "# Section 2. Description of the Input Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807af420",
   "metadata": {},
   "source": [
    "The input language of our command interpreter system revolves around a Poker Game RPG elements where players use text-based commands like (start, bet, fold, call, all, raise, buy, inspect, play, quit, use, etc.) to interact and manipulate the game. The language allows players to input basic game actions and special card manipulation commands. The design of our input language is heavily inspired by classic text-based adventure games such as Bookworm Adventures where textual inputs of users are used to progress through levels, trigger sequences, and perform strategic actions. The system solves and improves many features and problems of many traditional command-line games and text adventure games such as providing real-time feedback and execution of commands instead of relying on static, turn-based response or pre-scripted interactions. Creating a dynamic environment and game flow that enhances player immersion through a cause and effect response based on user input and logical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66761260",
   "metadata": {},
   "source": [
    "### **Input Language Structure:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b468aa27",
   "metadata": {},
   "source": [
    "**1. Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40affe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_COMMAND(t):\n",
    "    r'\\b(start|bet|fold|call|all|raise|buy|inspect|play|quit|use)\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6846863",
   "metadata": {},
   "source": [
    "Command Tokens: The basic commands that manipulate the course of the game's actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca703a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_NUMBER(t):\n",
    "    r'\\b\\d+\\b'\n",
    "    t.value = int(t.value)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb166b",
   "metadata": {},
   "source": [
    "Number Tokens: Tokenize integers and converts their text to Python ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38bee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_ALPHA_VAL(t):\n",
    "    r'\\b[jqka]\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cba5d7",
   "metadata": {},
   "source": [
    "Alpha Val Tokens: Recognizes face-card ranks as tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8786a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_CARD_ID(t):\n",
    "    r'\\b(?:[2-9]|10|[jqka])[hdsc]\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc15a33",
   "metadata": {},
   "source": [
    "Card ID Tokens: Recognizes playing-card identifiers (suits & values) as tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9503d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_ITEM_ID(t):\n",
    "    r'\\bi\\d+\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7a137",
   "metadata": {},
   "source": [
    "Item ID Tokens: Recognizes Item Ids as tokens to be bought at the shop or used in the form of community cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a7ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_SUIT(t):\n",
    "    r'\\b[hdsc]\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2cf41",
   "metadata": {},
   "source": [
    "Suit Tokens: Recognizes suit-card ranks as tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6c8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_CHANGE_KEY(t):\n",
    "    r'\\b(suit|value)\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c13e3",
   "metadata": {},
   "source": [
    "Change key Tokens: Recognizes as tokens and used in special commands to change card suits or values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feeabded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_ACTION(t):\n",
    "    r'\\b(change|reveal|exchange)\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5c4db",
   "metadata": {},
   "source": [
    "Action Tokens: Recognizes actions as tokens and used in special commands to change card, and reveal or exchange cards of opponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1882cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_TO(t):\n",
    "    r'\\bto\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4241b2",
   "metadata": {},
   "source": [
    "To Token: Emits a To token when it sees an input \"To\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d475137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_OF(t):\n",
    "    r'\\bof\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1f976",
   "metadata": {},
   "source": [
    "Of Token: Emits a Of token when it sees an input \"Of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb06d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_WITH(t):\n",
    "    r'\\bwith\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909625bd",
   "metadata": {},
   "source": [
    "With Token: Emits a With token when it sees an input \"With\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc62342",
   "metadata": {},
   "source": [
    "**2. Grammar/Syntax**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052edca3",
   "metadata": {},
   "source": [
    "Our grammar follows the following structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146a506",
   "metadata": {},
   "source": [
    "S -> command U | command .                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2e08f",
   "metadata": {},
   "source": [
    "U -> number | item_id | card_id A | card_id | card_id to P ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62067e6d",
   "metadata": {},
   "source": [
    "A -> card_id A | card_id ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49441111",
   "metadata": {},
   "source": [
    "P -> action | action C | act E | act V.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100380c",
   "metadata": {},
   "source": [
    "C -> change_key of card_id K| change_key of card_id ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099f78c",
   "metadata": {},
   "source": [
    "V -> card_id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eac793",
   "metadata": {},
   "source": [
    "K -> to R ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06843e89",
   "metadata": {},
   "source": [
    "R -> number | suit | alpha_val ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f19791",
   "metadata": {},
   "source": [
    "E -> F with F ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860f434",
   "metadata": {},
   "source": [
    "F -> card_id | number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23db95",
   "metadata": {},
   "source": [
    "**3. Valid/Invalid Statements**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973594e",
   "metadata": {},
   "source": [
    "Valid Statements are commands that are accepted based on the recognized tokens optionally followed by a syntactically correct target that also passes semantic checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6295c1",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ff5bb",
   "metadata": {},
   "source": [
    "• Basic Commands: Simple commands like bet 100, fold, quit, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7efb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(COMMAND,'bet',1,0)\n",
      "LexToken(NUMBER,50,1,4)\n"
     ]
    }
   ],
   "source": [
    "from interpreter.tokenizer import lexer\n",
    "input = \"bet 50\"\n",
    "lexer.input(input)\n",
    "for tok in lexer:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93dd6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(COMMAND,'fold',1,0)\n"
     ]
    }
   ],
   "source": [
    "input = \"fold\"\n",
    "lexer.input(input)\n",
    "for tok in lexer:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5151a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(COMMAND,'quit',1,0)\n"
     ]
    }
   ],
   "source": [
    "input = \"quit\"\n",
    "lexer.input(input)\n",
    "for tok in lexer:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2778b0",
   "metadata": {},
   "source": [
    "• Special Card Commands: Complex actions like use 5h to change suit of 3d to s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddcb648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(COMMAND,'use',1,0)\n",
      "LexToken(CARD_ID,'5h',1,4)\n",
      "LexToken(TO,'to',1,7)\n",
      "LexToken(ACTION,'change',1,10)\n",
      "LexToken(CHANGE_KEY,'suit',1,17)\n",
      "LexToken(OF,'of',1,22)\n",
      "LexToken(CARD_ID,'3d',1,25)\n",
      "LexToken(TO,'to',1,28)\n",
      "LexToken(SUIT,'s',1,31)\n"
     ]
    }
   ],
   "source": [
    "input = \"use 5h to change suit of 3d to s\"\n",
    "lexer.input(input)\n",
    "for tok in lexer:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ebbecf",
   "metadata": {},
   "source": [
    "Invalid Statements are commands that are not accepted based on the recognized tokens and doesn't follow any syntactically correct target and doesn't pass any semantic checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9875829",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269788d8",
   "metadata": {},
   "source": [
    "• Missing Syntax like bet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca76894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, 'Wrong target on the bet command! Must be a number.')\n"
     ]
    }
   ],
   "source": [
    "from interpreter.core import interpret_command\n",
    "print(interpret_command(\"Bet\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a91d6e8",
   "metadata": {},
   "source": [
    "Semantic error (Invalid Suit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9448df7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, \"TokError(value='x', position=32)\")\n"
     ]
    }
   ],
   "source": [
    "print(interpret_command(\"use 5h to change suit of 3d to 5x\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a80ba",
   "metadata": {},
   "source": [
    "Semantic error (Invalid card value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa2f6a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, 'Invalid value used in change action')\n"
     ]
    }
   ],
   "source": [
    "print(interpret_command(\"use 5h to change value of 3d to 15\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5b406",
   "metadata": {},
   "source": [
    "Lexical Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f63721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, \"TokError(value='c', position=6)\")\n"
     ]
    }
   ],
   "source": [
    "print(interpret_command(\"bet abc\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409fe42-03c8-4fb7-b6a8-874734c0005a",
   "metadata": {},
   "source": [
    "# Section 3. System Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a0e8b",
   "metadata": {},
   "source": [
    "Libraries and modules are collection of pre-written code that is designed to be reused, simplifying development and code organization. Within the Poker RPG command interpreter system, they serve the purpose of simplifying tokenizing and parsing, ensuring semantic validation across inputs, handling terminal UI, structure visualization, and game modularization and logic interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8e3ee",
   "metadata": {},
   "source": [
    "**1. Built-in libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732976e",
   "metadata": {},
   "source": [
    "Collection of prewritten codes that are automatically included within the programming language or application, ready-to-use without the need for external installation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052d3e1",
   "metadata": {},
   "source": [
    "Examples used within the Poker RPG Command Interpreter System:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "affd69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdcfbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import curses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5721fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curses import wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8c2fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ec6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b8e149",
   "metadata": {},
   "source": [
    "**2. Third-party libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa16cba",
   "metadata": {},
   "source": [
    "Collection of prewritten codes created by other developers or organizations that can be easily integrated within the programming language or application to add functionality without the need to develop it from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695cfa7",
   "metadata": {},
   "source": [
    "Examples used within the Poker RPG Command Interpreter System:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a881ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.yacc as yacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4064fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.lex as lex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642823f",
   "metadata": {},
   "source": [
    "**3. Project/local modules**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56dac24",
   "metadata": {},
   "source": [
    "Customized code units develop to organize, encapsulate, and reuse functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92902cb",
   "metadata": {},
   "source": [
    "Examples used within the Poker RPG Command Interpreter System:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42d287bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poker_game.state import State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bb63b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter.parser import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76717f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter.tokenizer import lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5220cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import interpreter.semantic_analyzer as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4f7cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import interpreter.tokenizer as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a6bc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter.tokenizer import tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "475dc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import interpreter.parser as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b51a2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ui.layout as layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54007122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ui.input as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14263335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poker_game.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "344a325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import interpreter.core as core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94d45f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter.semantic_analyzer import valid_semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5a0f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter.core import interpret_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7be49835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ui.terminal import add_terminal_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d00ef3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ui.terminal as term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adae9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ui.main_screen as ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7de9e9-38ce-45a4-b702-8e291ea3465b",
   "metadata": {},
   "source": [
    "# Section 4. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394365f",
   "metadata": {},
   "source": [
    "The overall architecture of our interpreter revolves around 3 main components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144f4b3",
   "metadata": {},
   "source": [
    "**1. Lexer (Tokenizer)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dbf642",
   "metadata": {},
   "source": [
    "Converts raw inputs into tokens, and is accepted based on the recognized commands, numbers, card IDs, suits, actions, and keywords whilst handling lexical errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec749a8",
   "metadata": {},
   "source": [
    "**2. Parser**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc013923",
   "metadata": {},
   "source": [
    "Uses LALR parsing (parser.out) with PLY to build Abstract Syntax Trees (ASTs) to validate syntax based on the defined grammar rules whilst handling syntax errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d58e1",
   "metadata": {},
   "source": [
    "**3. Executor (Interpreter Engine)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b2d53",
   "metadata": {},
   "source": [
    "Semantic Analyzer validates business logic and lets the core interpreter executes valid commands against game state, and returns appropriate responses or error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e2c18",
   "metadata": {},
   "source": [
    "**4. Data Flow Diagram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38c6aa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐\n",
      "    │ Input Text  │──▶ │ Tokenizer   │──▶│   Parser    │──▶│  Semantic   │──▶ │ Game State  │\n",
      "    │  \"bet 50\"   │    │  (Lexer)    │    │   (LALR)    │    │  Analyzer   │    │ (Execution) │\n",
      "    └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘\n",
      "                                                                                        │\n",
      "                                                                                        ▼\n",
      "                                                                                ┌─────────────┐\n",
      "                                                                                │   Output    │\n",
      "                                                                                │ \"Valid Cmd\" │\n",
      "                                                                                └─────────────┘\n",
      "\n",
      "    Error Paths:\n",
      "    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐\n",
      "    │   Lexical   │    │   Syntax    │    │  Semantic   │\n",
      "    │    Error    │    │    Error    │    │    Error    │\n",
      "    │  TokError   │    │ \"Synt Error\"│    │ \"Inv Syntax\"│\n",
      "    └─────────────┘    └─────────────┘    └─────────────┘\n",
      "           ▲                   ▲                   ▲\n",
      "           │                   │                   │\n",
      "    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐\n",
      "    │ Tokenizer   │    │   Parser    │    │  Semantic   │\n",
      "    └─────────────┘    └─────────────┘    └─────────────┘\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def create_data_flow_diagram():\n",
    "    print(\"\"\"\n",
    "    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐\n",
    "    │ Input Text  │──▶ │ Tokenizer   │──▶│   Parser    │──▶│  Semantic   │──▶ │ Game State  │\n",
    "    │  \"bet 50\"   │    │  (Lexer)    │    │   (LALR)    │    │  Analyzer   │    │ (Execution) │\n",
    "    └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘\n",
    "                                                                                        │\n",
    "                                                                                        ▼\n",
    "                                                                                ┌─────────────┐\n",
    "                                                                                │   Output    │\n",
    "                                                                                │ \"Valid Cmd\" │\n",
    "                                                                                └─────────────┘\n",
    "    \n",
    "    Error Paths:\n",
    "    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐\n",
    "    │   Lexical   │    │   Syntax    │    │  Semantic   │\n",
    "    │    Error    │    │    Error    │    │    Error    │\n",
    "    │  TokError   │    │ \"Synt Error\"│    │ \"Inv Syntax\"│\n",
    "    └─────────────┘    └─────────────┘    └─────────────┘\n",
    "           ▲                   ▲                   ▲\n",
    "           │                   │                   │\n",
    "    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐\n",
    "    │ Tokenizer   │    │   Parser    │    │  Semantic   │\n",
    "    └─────────────┘    └─────────────┘    └─────────────┘\n",
    "    \"\"\")\n",
    "\n",
    "create_data_flow_diagram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4db0bb",
   "metadata": {},
   "source": [
    "**5. Error Handling Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe76660",
   "metadata": {},
   "source": [
    "• Lexical Errors: Handles input mistakes such as invalid characters and command mispositions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd67cfcb",
   "metadata": {},
   "source": [
    "• Syntax Errors: Handles spelling mistakes such as malformed commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9c938",
   "metadata": {},
   "source": [
    "• Semantic Errors: Handles logical errors such as invalid game mechanics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0142f",
   "metadata": {},
   "source": [
    "**6. Design Justification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5d50c",
   "metadata": {},
   "source": [
    "Python Lex-Yacc: Industry-standard parsing library that handles complex grammars efficiently and provides excellent error reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e7985",
   "metadata": {},
   "source": [
    "Look-Ahead LR: Balances parsing power with efficiency, suitable for the command language's complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f316d",
   "metadata": {},
   "source": [
    "Lexer, Parser, and Executor: Allows independent testing and modification of each component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b86b1c",
   "metadata": {},
   "source": [
    "Semantic Validation: Ensures game integrity by validating business rules beyond syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b7f03-aa1d-4885-9644-80494c8df3ee",
   "metadata": {},
   "source": [
    "# Section 5. Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d3821d",
   "metadata": {},
   "source": [
    "In this section, we will be explaining the step-by-step implementation of our interpreter. On how we identify and categorize tokens, up to how the system responds to invalid inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116c0c2",
   "metadata": {},
   "source": [
    "**1. Lexer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed3b53",
   "metadata": {},
   "source": [
    "We start the process by importing the necessary libraries and modules and handling the following dataclass to represent the tokenization errors when an invalid characters doesn't match any defined token patters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbb81a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.lex as lex\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TokError:\n",
    "    value: object\n",
    "    position: int\n",
    "\n",
    "error = None\n",
    "error_found = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d02c9",
   "metadata": {},
   "source": [
    "Then we declare the token definitions that will serve as the commands and valid inputs to change the game's actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9cadd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = (\n",
    "    'COMMAND',\n",
    "    'NUMBER',\n",
    "    'ALPHA_VAL',\n",
    "    'CARD_ID',\n",
    "    'ITEM_ID',\n",
    "    'SUIT',\n",
    "    'CHANGE_KEY',\n",
    "    'ACTION',\n",
    "    'TO',\n",
    "    'OF',\n",
    "    'WITH',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48092414",
   "metadata": {},
   "source": [
    "Then we declare the token recognition functions, which are necessary so that these tokens can return to the parser for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5619fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_COMMAND(t):\n",
    "    r'\\b(start|bet|fold|call|all|raise|buy|inspect|play|quit|use)\\b'\n",
    "    return t\n",
    "\n",
    "def t_NUMBER(t):\n",
    "    r'\\b\\d+\\b'\n",
    "    t.value = int(t.value)\n",
    "    return t\n",
    "\n",
    "def t_ALPHA_VAL(t):\n",
    "    r'\\b[jqka]\\b'\n",
    "    return t\n",
    "\n",
    "def t_CARD_ID(t):\n",
    "    r'\\b(?:[2-9]|10|[jqka])[hdsc]\\b'\n",
    "    return t\n",
    "\n",
    "def t_ITEM_ID(t):\n",
    "    r'\\bi\\d+\\b'\n",
    "    return t\n",
    "\n",
    "\n",
    "def t_SUIT(t):\n",
    "    r'\\b[hdsc]\\b'\n",
    "    return t\n",
    "\n",
    "def t_CHANGE_KEY(t):\n",
    "    r'\\b(suit|value)\\b'\n",
    "    return t\n",
    "\n",
    "\n",
    "def t_ACTION(t):\n",
    "    r'\\b(change|reveal|exchange)\\b'\n",
    "    return t\n",
    "\n",
    "\n",
    "def t_TO(t):\n",
    "    r'\\bto\\b'\n",
    "    return t\n",
    "\n",
    "def t_OF(t):\n",
    "    r'\\bof\\b'\n",
    "    return t\n",
    "\n",
    "def t_WITH(t):\n",
    "    r'\\bwith\\b'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e5ccee",
   "metadata": {},
   "source": [
    "Then we have a code block that handles the input function and prints the characters that are converted into recognizable tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71c8d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(COMMAND,'buy',1,0)\n",
      "LexToken(NUMBER,10923,1,4)\n"
     ]
    }
   ],
   "source": [
    "#Test case for tokenizer.py\n",
    "import builtins\n",
    "from src.interpreter.tokenizer import lexer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = builtins.input(\"Enter command: \")\n",
    "    lexer.input(data)\n",
    "    for tok in lexer:\n",
    "        print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847acfb",
   "metadata": {},
   "source": [
    "**2. Parser**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6d60f",
   "metadata": {},
   "source": [
    "The process starts similarly at first by importing the necessary libraries and modules for taking input data and transforming them into a structured format that the interpreter can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a70b918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ply.lex import LexToken\n",
    "from interpreter.tokenizer import tokens\n",
    "import ply.yacc as yacc\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96348127",
   "metadata": {},
   "source": [
    "Then we create the Abstract Syntax Trees (AST) that will serve as the representation of the parsed commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2032b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Command:\n",
    "    command: str\n",
    "    target: object = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Number:\n",
    "    num: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AlphabetValue:\n",
    "    value: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Suit:\n",
    "    value: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ItemID:\n",
    "    item: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CardID:\n",
    "    value: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "    action: str\n",
    "    target: object = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SpecialCardCommand:\n",
    "    special_card: CardID\n",
    "    action: Action\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChangeTarget:\n",
    "    change_key: str\n",
    "    card_id: CardID\n",
    "    change_value: str = 'random'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExchangeTarget:\n",
    "    target1: object\n",
    "    target2: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd44e70",
   "metadata": {},
   "source": [
    "Then we implement the grammar rule functions that handle the parsing logic for our Poker RPG interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b7fb3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_s1(p):\n",
    "    'S :  COMMAND U'\n",
    "    p[0] = Command(command=p[1], target=p[2])\n",
    "\n",
    "\n",
    "def p_s2(p):\n",
    "    'S : COMMAND'\n",
    "    p[0] = Command(command=p[1])\n",
    "\n",
    "\n",
    "def p_u1(p):\n",
    "    'U : NUMBER'\n",
    "    p[0] = Number(p[1])\n",
    "\n",
    "\n",
    "def p_u2(p):\n",
    "    'U : ITEM_ID'\n",
    "    p[0] = ItemID(p[1])\n",
    "\n",
    "\n",
    "def p_u3(p):\n",
    "    'U : CARD_ID A'\n",
    "    p[0] = [CardID(value=p[1])] + p[2]\n",
    "\n",
    "\n",
    "def p_u4(p):\n",
    "    'U : CARD_ID'\n",
    "    p[0] = CardID(value=p[1])\n",
    "\n",
    "\n",
    "def p_u5(p):\n",
    "    'U : CARD_ID TO P'\n",
    "    p[0] = SpecialCardCommand(CardID(p[1]), p[3])\n",
    "\n",
    "\n",
    "def p_a1(p):\n",
    "    'A : CARD_ID A'\n",
    "    p[0] = [CardID(value=p[1])] + p[2]\n",
    "\n",
    "\n",
    "def p_a2(p):\n",
    "    'A : CARD_ID'\n",
    "    p[0] = [CardID(value=p[1])]\n",
    "\n",
    "\n",
    "def p_p1(p):\n",
    "    'P : ACTION'\n",
    "    p[0] = Action(action=p[1])\n",
    "\n",
    "\n",
    "def p_p2(p):\n",
    "    'P : ACTION C'\n",
    "    p[0] = Action(action=p[1], target=p[2])\n",
    "\n",
    "\n",
    "def p_p3(p):\n",
    "    'P : ACTION E'\n",
    "    p[0] = Action(action=p[1], target=p[2])\n",
    "\n",
    "\n",
    "def p_p4(p):\n",
    "    'P : ACTION V'\n",
    "    p[0] = Action(action=p[1], target=p[2])\n",
    "\n",
    "\n",
    "def p_c1(p):\n",
    "    'C : CHANGE_KEY OF CARD_ID K'\n",
    "    p[0] = ChangeTarget(change_key=p[1], card_id=CardID(value=p[3]), change_value=p[4])\n",
    "\n",
    "\n",
    "def p_c2(p):\n",
    "    'C : CHANGE_KEY OF CARD_ID'\n",
    "    p[0] = ChangeTarget(change_key=p[1], card_id=CardID(value=p[3]))\n",
    "\n",
    "\n",
    "def p_k(p):\n",
    "    'K : TO R'\n",
    "    p[0] = p[2]\n",
    "\n",
    "\n",
    "def p_r1(p):\n",
    "    'R : NUMBER'\n",
    "    p[0] = Number(num=p[1])\n",
    "\n",
    "\n",
    "def p_r2(p):\n",
    "    'R : SUIT'\n",
    "    p[0] = Suit(value=p[1])\n",
    "\n",
    "\n",
    "def p_r3(p):\n",
    "    'R : ALPHA_VAL'\n",
    "    p[0] = AlphabetValue(value=p[1])\n",
    "\n",
    "\n",
    "def p_e(p):\n",
    "    'E : F WITH F'\n",
    "    p[0] = ExchangeTarget(p[1], p[3])\n",
    "\n",
    "\n",
    "def p_f1(p):\n",
    "    'F : NUMBER'\n",
    "    p[0] = Number(num=p[1])\n",
    "\n",
    "\n",
    "def p_f2(p):\n",
    "    'F : CARD_ID'\n",
    "    p[0] = CardID(value=p[1])\n",
    "\n",
    "\n",
    "def p_v(p):\n",
    "    'V : NUMBER'\n",
    "    p[0] = Number(num=p[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6287c2",
   "metadata": {},
   "source": [
    "Lastly, we create the parser object that will parse the user input into the Abstract Syntax Tree (AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8975e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Case for parser.py\n",
    "import sys\n",
    "from io import StringIO\n",
    "from src.interpreter.parser import parser\n",
    "debug_output = StringIO()\n",
    "sys.stdout = debug_output\n",
    "command = \"bet 100\"\n",
    "ast = parser.parse(command)\n",
    "sys.stdout = sys.__stdout__\n",
    "print(\"Debug output:\")\n",
    "print(debug_output.getvalue())\n",
    "print(f\"AST: {ast}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa95445",
   "metadata": {},
   "source": [
    "**3. Executor**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1eaf49",
   "metadata": {},
   "source": [
    "The process starts by importing the necessary libraries and modules for command validation to modify the game state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ae6fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poker_game.state import State\n",
    "from interpreter.parser import parser\n",
    "from interpreter.tokenizer import lexer\n",
    "import interpreter.semantic_analyzer as s\n",
    "import interpreter.tokenizer as t\n",
    "import poker_game.commands as commands\n",
    "import poker_game.special_commands as special_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eaaf4f",
   "metadata": {},
   "source": [
    "Then we tokenize the inputs which will then parse them into ASTs, and we validate the semantics before executing the commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e256af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_command(input: str, state: State):\n",
    "    input = input.lower()\n",
    "\n",
    "    lexer.input(input)\n",
    "\n",
    "    ast = parser.parse(input)\n",
    "    valid = s.valid_semantics(ast)\n",
    "\n",
    "    if not valid[0]:\n",
    "        return valid[1]\n",
    "\n",
    "    command = ast.command\n",
    "\n",
    "    match command:\n",
    "        case \"start\":\n",
    "            commands.Start(state)\n",
    "            return f\"Game Started is {state.started}\"\n",
    "        case _:\n",
    "            # if tapos na lahat ng commands, dapat unreachble toh\n",
    "            return \"Unknown Valid Command\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e58e2-c351-4daa-98f7-282406c632a2",
   "metadata": {},
   "source": [
    "# Section 6. Testing with Valid and Invalid Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fad4bb",
   "metadata": {},
   "source": [
    "In this section, we will be demonstrating how our interpreter works by running a variety of test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c8adc",
   "metadata": {},
   "source": [
    "### Section 6.1 Valid Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390c1e6",
   "metadata": {},
   "source": [
    "**1. Import Libraries and Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fcb5beae-7361-4c08-8665-255527484070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter.tokenizer import lexer\n",
    "from interpreter.parser import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a6888",
   "metadata": {},
   "source": [
    "**2. Basic Commands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b891c94-c6d7-43d4-b731-aec810322ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer.input('raise 1500')\n",
    "for tok in lexer:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab496da9",
   "metadata": {},
   "source": [
    "**3. Special Commands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09cd4b54-fb6c-4201-9b7b-feeeb0cc2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = parser.parse('use 5h to reveal 0')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d8670",
   "metadata": {},
   "source": [
    "**4. Abstract Syntax Trees Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b85872-66fa-4071-9fbd-648603c072c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter.tokenizer import lexer\n",
    "from interpreter.parser import parser\n",
    "from graphviz import Digraph\n",
    "import interpreter.parser as p\n",
    "\n",
    "def create_ast(out):\n",
    "\n",
    "    dot = Digraph('Abstract Syntax Tree') \n",
    "    \n",
    "    nodes = []\n",
    "    edges = []\n",
    "    \n",
    "    nodes.append(out.command)\n",
    "    \n",
    "    if out.target:\n",
    "        t = out.target\n",
    "        if type(t) == list:\n",
    "            for i, card in enumerate(t):\n",
    "                nodes.append(card.value + str(i))\n",
    "                edges.append((out.command, card.value + str(i)))\n",
    "        if type(t) == p.Number:\n",
    "            nodes.append(str(t.num))\n",
    "            edges.append((out.command, str(t.num)))\n",
    "        if type(t) == p.CardID:\n",
    "            nodes.append(str(t.value))\n",
    "            edges.append((out.command, str(t.value)))\n",
    "        if type(t) == p.ItemID:\n",
    "            nodes.append(str(t.item))\n",
    "            edges.append((out.command, str(t.item)))\n",
    "        if type(t) == p.SpecialCardCommand:\n",
    "            a = t.action.action + \"\\n\" + t.special_card.value\n",
    "            nodes.append(a)\n",
    "            edges.append((out.command, a))\n",
    "            at = t.action.target\n",
    "            if at:\n",
    "                if type(at) == p.ChangeTarget:\n",
    "                    nodes.append(\"change_key\\n \" + at.change_key)\n",
    "                    edges.append((a, \"change_key\\n \" + at.change_key))\n",
    "                    edges.append((a, \"card\\n \" + str(at.card_id)))\n",
    "                    if type(at.change_value) == p.Number:\n",
    "                        nodes.append(\"change_value\\n \" + str(at.change_value.num))\n",
    "                        edges.append((a, \"change_value\\n \" + str(at.change_value.num)))\n",
    "                    if type(at.change_value) == p.AlphabetValue or type(at.change_value) == p.Suit:\n",
    "                        nodes.append(\"change_value\\n \" + str(at.change_value.value))\n",
    "                        edges.append((a, \"change_value\\n \" + str(at.change_value.value)))\n",
    "    \n",
    "                if type(at) == p.ExchangeTarget:\n",
    "                    def target_value(target):\n",
    "                        if type(target) == p.Number:\n",
    "                            return str(target.num)\n",
    "                        if type(target) == p.CardID:\n",
    "                            return target.value\n",
    "                    nodes.append(\"target 1\\n \" + target_value(at.target1))\n",
    "                    edges.append((a, \"target 1\\n \" + target_value(at.target1)))\n",
    "                    nodes.append(\"target 2\\n \" + target_value(at.target2))\n",
    "                    edges.append((a, \"target 2\\n \" + target_value(at.target2)))\n",
    "                    \n",
    "                \n",
    "    \n",
    "    for node in nodes:\n",
    "        dot.node(node, node)\n",
    "    \n",
    "    for src, dst in edges:\n",
    "        dot.edge(src, dst)\n",
    "    \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b4f04ca-68a6-41bf-8347-0f204f7098bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.1 (20251006.0113)\n",
       " -->\n",
       "<!-- Title: Abstract Syntax Tree Pages: 1 -->\n",
       "<svg width=\"462pt\" height=\"232pt\"\n",
       " viewBox=\"0.00 0.00 462.00 232.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 227.97)\">\n",
       "<title>Abstract Syntax Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227.97 458.13,-227.97 458.13,4 -4,4\"/>\n",
       "<!-- use -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>use</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"195.92\" cy=\"-205.97\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"195.92\" y=\"-200.92\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">use</text>\n",
       "</g>\n",
       "<!-- change\n",
       "4s -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>change\n",
       "4s</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"195.92\" cy=\"-122.97\" rx=\"38.36\" ry=\"28.99\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"195.92\" y=\"-126.17\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">change</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"195.92\" y=\"-109.67\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4s</text>\n",
       "</g>\n",
       "<!-- use&#45;&gt;change\n",
       "4s -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>use&#45;&gt;change\n",
       "4s</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.92,-187.79C195.92,-180.7 195.92,-172.17 195.92,-163.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.42,-163.79 195.92,-153.79 192.42,-163.79 199.42,-163.79\"/>\n",
       "</g>\n",
       "<!-- change_key\n",
       " suit -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>change_key\n",
       " suit</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"56.92\" cy=\"-28.99\" rx=\"56.92\" ry=\"28.99\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"56.92\" y=\"-32.19\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">change_key</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"56.92\" y=\"-15.69\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"> suit</text>\n",
       "</g>\n",
       "<!-- change\n",
       "4s&#45;&gt;change_key\n",
       " suit -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>change\n",
       "4s&#45;&gt;change_key\n",
       " suit</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.46,-103.14C148.15,-90.36 122.27,-73.24 100.4,-58.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.53,-55.97 92.26,-53.37 98.66,-61.81 102.53,-55.97\"/>\n",
       "</g>\n",
       "<!-- change_value\n",
       " d -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>change_value\n",
       " d</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"195.92\" cy=\"-28.99\" rx=\"63.82\" ry=\"28.99\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"195.92\" y=\"-32.19\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">change_value</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"195.92\" y=\"-15.69\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"> d</text>\n",
       "</g>\n",
       "<!-- change\n",
       "4s&#45;&gt;change_value\n",
       " d -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>change\n",
       "4s&#45;&gt;change_value\n",
       " d</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.92,-93.63C195.92,-86.11 195.92,-77.85 195.92,-69.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.42,-69.92 195.92,-59.92 192.42,-69.92 199.42,-69.92\"/>\n",
       "</g>\n",
       "<!-- card\n",
       " CardID(value=&#39;3h&#39;) -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>card\n",
       " CardID(value=&#39;3h&#39;)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"365.92\" cy=\"-28.99\" rx=\"88.21\" ry=\"28.99\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"365.92\" y=\"-32.19\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">card</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"365.92\" y=\"-15.69\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"> CardID(value=&#39;3h&#39;)</text>\n",
       "</g>\n",
       "<!-- change\n",
       "4s&#45;&gt;card\n",
       " CardID(value=&#39;3h&#39;) -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>change\n",
       "4s&#45;&gt;card\n",
       " CardID(value=&#39;3h&#39;)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M226.71,-105.32C250.14,-92.64 283.01,-74.85 310.93,-59.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"312.5,-62.87 319.63,-55.04 309.17,-56.72 312.5,-62.87\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x224686dc6e0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = parser.parse('use 4s to change suit of 3h to d')\n",
    "create_ast(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ffa8c",
   "metadata": {},
   "source": [
    "### Section 6.2 Invalid Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d749797b",
   "metadata": {},
   "source": [
    "**1. Missing Syntax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce669c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid raise command\n"
     ]
    }
   ],
   "source": [
    "print(interpret_command(\"Raise\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551ac50",
   "metadata": {},
   "source": [
    "**2. Semantic Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f79844e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange target must be an integer between 0 and 4\n"
     ]
    }
   ],
   "source": [
    "print(interpret_command(\"Use 5h to exchange 5 with 4s\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26677549",
   "metadata": {},
   "source": [
    "**3. Lexical Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23a87014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokError(value='c', position=6)\n"
     ]
    }
   ],
   "source": [
    "print(interpret_command(\"buy abc\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b19d7ae",
   "metadata": {},
   "source": [
    "### Section 6.3 How these test cases proved the correctness and robustness of your interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd66a1f",
   "metadata": {},
   "source": [
    "Test cases like these are important for validating the functionality and application of the interpreter, additionally, it also validates the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6a182",
   "metadata": {},
   "source": [
    "• Tests invalid characters and token recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a0823",
   "metadata": {},
   "source": [
    "• Tests grammar rule violations and abnormal structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcd89b",
   "metadata": {},
   "source": [
    "• Tests logical errors in valid syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326bb10",
   "metadata": {},
   "source": [
    "• Ensures commands work regardless of input cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c63023",
   "metadata": {},
   "source": [
    "• Verifies actions within the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48362e-4d51-49d6-93de-dc9d69f34aac",
   "metadata": {},
   "source": [
    "# Section 7. Extensions and Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a14854-cb64-4e99-b463-a548ea7cd75b",
   "metadata": {},
   "source": [
    "# Section 8. Insights and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77644a9-ee72-465d-a2e3-e65ec60e1dc7",
   "metadata": {},
   "source": [
    "# Section 9. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4597ef",
   "metadata": {},
   "source": [
    "GeeksforGeeks. (2022, February 16). PLY (Python lex-Yacc) - An Introduction. GeeksforGeeks, Sanchhaya Education Private Limited. https://www.geeksforgeeks.org/python/ply-python-lex-yacc-an-introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04efcf",
   "metadata": {},
   "source": [
    "GeeksforGeeks. (2025, July 11). Data Classes in Python | An Introduction. GeeksforGeeks, Sanchhaya Education Private Limited. https://www.geeksforgeeks.org/python/data-classes-in-python-an-introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771520d",
   "metadata": {},
   "source": [
    "GeeksforGeeks. (2025, July 23). Python String Module. GeeksforGeeks, Sanchhaya Education Private Limited. https://www.geeksforgeeks.org/python/python-string-module/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e87538",
   "metadata": {},
   "source": [
    "GeeksforGeeks. (2025, October 1). Python curses Module. GeeksforGeeks, Sanchhaya Education Private Limited. https://www.w3schools.com/Python/ref_module_curses.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d319e8",
   "metadata": {},
   "source": [
    "GeeksforGeeks. (2025, September 8). Pathlib module in Python. GeeksforGeeks, Sanchhaya Education Private Limited. https://www.geeksforgeeks.org/python/pathlib-module-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c4ed9",
   "metadata": {},
   "source": [
    "Jade, E. (2024, July 13). Step-by-Step: Building a Lexer in Java for Tokenizing Source Code. Medium. https://medium.com/@enzojade62/step-by-step-building-a-lexer-in-java-for-tokenizing-source-code-ac4f1d91326f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9093e75",
   "metadata": {},
   "source": [
    "Python. (2022, March 10). tomllib — Parse TOML files. The Python Software Foundation. https://docs.python.org/3/library/tomllib.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a1428",
   "metadata": {},
   "source": [
    "Python. (2025, March 23). token — Constants used with Python parse trees. The Python Software Foundation. https://docs.python.org/3/library/token.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
